version: '3.8'

services:
  # Text Embeddings Inference (TEI) - Local embedding generation
  tei:
    image: ghcr.io/huggingface/text-embeddings-inference:cpu-latest
    container_name: contextd-tei
    ports:
      - "8080:80"
    volumes:
      - tei-data:/data
    environment:
      - MODEL_ID=${TEI_MODEL_ID:-BAAI/bge-small-en-v1.5}
    command: --model-id ${TEI_MODEL_ID:-BAAI/bge-small-en-v1.5}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:80/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    restart: unless-stopped

  # Qdrant - Vector database for semantic search
  qdrant:
    image: qdrant/qdrant:latest
    container_name: contextd-qdrant
    ports:
      - "6333:6333"  # HTTP API
      - "6334:6334"  # gRPC API
    volumes:
      - qdrant-data:/qdrant/storage
    # Health check disabled - Qdrant image doesn't include curl/wget
    # Service is monitored via application-level health checks instead
    restart: unless-stopped

volumes:
  tei-data:
    driver: local
  qdrant-data:
    driver: local
