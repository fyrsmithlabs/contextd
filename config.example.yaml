# config.example.yaml
# Contextd Configuration
# Copy to ~/.config/contextd/config.yaml and modify as needed.
# File MUST have 0600 permissions: chmod 600 ~/.config/contextd/config.yaml
#
# Environment variables override file values.
# Mapping: SECTION_FIELD_NAME -> section.field_name
# Example: SERVER_HTTP_PORT -> server.http_port

# Server Configuration
server:
  http_port: 9090              # HTTP server port (default: 9090)
  shutdown_timeout: 10s        # Graceful shutdown timeout (default: 10s)

# Observability Configuration (OpenTelemetry)
# contextd exports metrics and traces via OTLP to an OpenTelemetry Collector
# or directly to compatible backends (VictoriaMetrics, Jaeger, etc.)
observability:
  enabled: false               # Enable OTEL telemetry (default: false)
  endpoint: localhost:4317     # OTLP endpoint (default: localhost:4317)
  protocol: grpc               # Protocol: "grpc" or "http/protobuf" (default: grpc)
  insecure: true               # Use insecure connection (only for localhost)
  tls_skip_verify: false       # Skip TLS certificate verification (for internal CAs)
  service_name: contextd       # Service name for traces (default: contextd)
  service_version: 0.1.0       # Service version (default: 0.1.0)

  # Sampling configuration (for traces)
  sampling:
    rate: 1.0                  # Sampling rate 0.0-1.0 (default: 1.0 = 100%)
    always_on_errors: true     # Always capture error traces (default: true)

  # Metrics configuration
  metrics:
    enabled: true              # Enable metrics export (default: true)
    export_interval: 15s       # Metrics export interval (default: 15s)

  # Shutdown configuration
  shutdown:
    timeout: 5s                # Graceful shutdown timeout (default: 5s)

# Pre-Fetch Configuration
# Proactively loads context based on git state
prefetch:
  enabled: true                # Enable pre-fetch engine (default: true)
  cache_ttl: 5m                # Cache TTL (default: 5m)
  cache_max_entries: 100       # Maximum cache entries (default: 100)

  # Individual rule configuration (optional, defaults shown)
  # rules:
  #   branch_diff:
  #     enabled: true
  #     max_files: 10
  #     max_size_kb: 50
  #     timeout_ms: 1000
  #   recent_commit:
  #     enabled: true
  #     max_size_kb: 20
  #     timeout_ms: 500
  #   common_files:
  #     enabled: true
  #     max_files: 3
  #     timeout_ms: 500

# Checkpoint Configuration
checkpoint:
  max_content_size_kb: 1024    # Maximum content size in KB (default: 1024 = 1MB)

# Consolidation Scheduler Configuration
# Automatically consolidates similar memories on a schedule
consolidation_scheduler:
  enabled: false               # Enable automatic consolidation (default: false)
  interval: 24h                # Time between consolidation runs (default: 24h)
  similarity_threshold: 0.8    # Similarity threshold for consolidation (default: 0.8)

# Qdrant Configuration (Vector Database)
qdrant:
  host: localhost              # Qdrant server host (default: localhost)
  port: 6334                   # Qdrant gRPC port (default: 6334)
  collection_name: contextd_default  # Collection name (default: contextd_default)
  vector_size: 384             # Vector dimensions (default: 384 for bge-small-en-v1.5)

# Embeddings Configuration (TEI Service)
embeddings:
  base_url: http://localhost:8080  # TEI server URL (default: http://localhost:8080)
  model: BAAI/bge-small-en-v1.5    # Embedding model (default: BAAI/bge-small-en-v1.5)

# Extraction Configuration (LLM for Memory Consolidation)
# ⚠️  SECURITY: Never commit API keys to version control!
# API keys should be set via environment variables, not in this file.
# If you must use this file, ensure it has 0600 permissions: chmod 0600 ~/.config/contextd/config.yaml
extraction:
  provider: disabled               # LLM provider: "anthropic", "openai", or "disabled" (default: disabled)
  anthropic_api_key: ""            # Anthropic API key (env: EXTRACTION_ANTHROPIC_API_KEY)
  anthropic_model: claude-3-5-sonnet-20241022  # Anthropic model (default: claude-3-5-sonnet-20241022)
  openai_api_key: ""               # OpenAI API key (env: EXTRACTION_OPENAI_API_KEY)
  openai_model: gpt-4              # OpenAI model (default: gpt-4)
  timeout: 30s                     # Request timeout (default: 30s)
  max_retries: 3                   # Maximum retry attempts (default: 3)

# Example environment variable overrides:
# export SERVER_HTTP_PORT=8080
# export SERVER_SHUTDOWN_TIMEOUT=30s
# export OBSERVABILITY_ENABLE_TELEMETRY=true
# export OBSERVABILITY_SERVICE_NAME=my-contextd
# export PREFETCH_ENABLED=false
# export PREFETCH_CACHE_TTL=10m
# export CHECKPOINT_MAX_CONTENT_SIZE_KB=2048
# export CONSOLIDATION_SCHEDULER_ENABLED=true
# export CONSOLIDATION_SCHEDULER_INTERVAL=12h
# export CONSOLIDATION_SCHEDULER_SIMILARITY_THRESHOLD=0.85
# export QDRANT_HOST=qdrant.example.com
# export QDRANT_PORT=6334
# export EMBEDDINGS_BASE_URL=http://tei.example.com:8080
# export EMBEDDINGS_MODEL=BAAI/bge-small-en-v1.5
# export EXTRACTION_PROVIDER=anthropic
# export EXTRACTION_ANTHROPIC_API_KEY=sk-ant-api03-...
# export EXTRACTION_ANTHROPIC_MODEL=claude-3-5-sonnet-20241022
# export EXTRACTION_OPENAI_API_KEY=sk-...
# export EXTRACTION_OPENAI_MODEL=gpt-4
# export EXTRACTION_TIMEOUT=30s
# export EXTRACTION_MAX_RETRIES=3
